# Fast Entropy Coding
诸如CABAC之类的熵编码本质上是一个顺序的任务，不适合并行化。因此，熵编码的性能通常是视频编码性能的瓶颈。CABAC引擎的性能优化可以提高整体编码的吞吐量。Zhou等人[^1]在论文中提供了一个例子：通过预规范化（*pre-normalization*）、混合路径覆盖、和旁路二值化（*bypass bin*）拆分，可提高34％的吞吐量。通过使用状态双转换方案减少关键路径从而盖上上下文的建模性能，实现在330 MHz的65 nm的视频编码器芯片上进行实时超高清电视视频编码。

## 熵编码内容补充
熵编码是视频编码的最后一步和解码的第一步所使用的一种无损编码。熵编码所处理的对象，是在前期的预测、变换阶段所产生的一系列语法元素(Syntax Elements)，包括预测模式和残差数据等。这些语法元素描述了CU，PU，TU和LF等多种语法元素的特性。对CU，有块结构信息以及帧内/帧间预测模式；对PU，描述了帧内预测模式和运动信息等；对TU，主要包含残差信息的变换系数等；LF语法元素在每一个最大编码单元LCU中传输一次，描述了环路滤波中SAO的类型和偏移量。CABAC主要包括三大步骤，即二值化、上下文建模和算数编码。

* 二值化：二值化的作用是将语法元素映射为二进制符号(bin)。HEVC中的二值化采用几种不同的方式，与H.264类似，主要有一元(Unary)，截断一元(Truncated Unary)，k阶指数哥伦布编码(EGK)和定长(Fixed Length)。这几种不同模式的区别体现在将某个无符号整数N二值化的结果的不同，具体该表中的例子表述了大部分情况所采用的二值化方法，另外可能存在多种方法的组合，以及一些特定化的二值化方法。在实际应用中，具体采用哪一种二值化模式取决于语法元素的类型，或者之前处理过的语法元素的值以及条带参数中的设置。
* 上下文模型：CABAC之所以在压缩比率上可以取得巨大提高，关键就是因为上下文模型的引入为编码过程提供了精确的概率估计。CABAC采用的上下文模型是高度自适应的，不同二进制码元采用的模型不同，而且可以依据之前处理的二值化码流进行模型更新。每一个bin的上下文模型的选择依据包括语法元素类型、bin的位置、亮度/色度和相邻块信息等。CABAC的概率模型采用7bit结构，其中6bit的概率状态位和1bit的最大概率模型位，在HEVC中其概率模型更新方法与H.264的类似，而改进了上下文选择的逻辑以提高数据处理效率。
* 算数编码：算数编码是一种基于区间的递归划分的熵编码方法。一个初始化为[0,1]的区间根据bin的概率分布划分为两个子区间，并且依照bin的取值选取两个区间之一。该区间更新为选择的子区间，并进行下一次分割，依此循环往复。为防止下溢出，当区间长度小于某个值时，停止递归并重新进行区间归一化。在编码的过程中，可以使用概率估计（上下文编码）和等概率模式（旁路编码）。旁路编码中，区间划分由某个偏移量实现，而上下文编码的bin需查表。HEVC的编码过程与H.264类似。

[^1]: J. Zhou, D. Zhou, W. Fei, and S. Goto, “A High Performance CABAC Encoder Architecture for HEVC and H.264/AVC.

