# Subjective Video Quality Evaluation
视频处理系统需要执行各种任务，包括视频信号采集，压缩，恢复（*restoration*），增强（*enhancement*）和再现（*reproduction*）。在这些任务中，为了在可用的系统资源的约束下获得最佳视频质量，系统设计者通常基于某些质量标准进行各种权衡。

衡量质量的一个明显方法就是是征求人类的意见。因此，视频质量的主观评价方法就是利用人类受试者来执行评估视觉质量的任务。但是，主观评估应用程序处理的每个视频的质量是一件不可能的事情。此外，由于不同的人类观察者对质量判断存在天然的不一致性，通常需要从多个角度进行评估以便使得主观研究更有意义。此外，观察者的观看条件也会影响对视频质量的主观感受。这些观看条件包括：环境照明，显示设备，观看距离等。因此，必须在精心控制的环境中进行视频质量评估的主观研究。

尽管可以使用主观评估技术来跟踪真实的感知视频质量，但是该过程是一个繁琐的、非自动化的过程。并且因为不同的个体对相同的视觉对象有不同的感知，因此主观评估的结果可能会随着观看者的不同而变化。尽管如此，主观评价方法仍然是一种有价值的方法，并且可以为自动评估或客观视频质量评估算法提供参考。

可以用客观算法来估计用户的感知，并且可以使用主观测试的结果评估客观算法的性能。媒体降级（*media degradations*）会影响观众的感知质量。因此，必须精心设计主观测试，从而能够准确捕捉退化对用户感知的影响。主观测试需要进行全面的实验，以产生一致的结果。为了准确评估客观质量算法，主观测试需要包含如下方面：

* 参与主观评估的用户必须是无专业知识的非专家的普通用户。利用客观质量模型来评估参与用户的感知。参与用户按照测试设计者的指示对主观质量进行投票。但是，对于特定应用（例如开发新的编解码器），选择有经验的参与用户更为合适。
* 对于每个视频测试样本而言，参与主观评估的用户数量应该符合ITU-T相关建议中给定要求，一般而言，参与用户数至少是24人。
* 为了保证实验的一致性和可重复性，同时为了在实验中可以调整质量范围和失真类型，实验需要一个参考样本库（*anchor[^1] pool of samples*），该样本库能够代表需要评估的特定应用。因为并非总能在参考条件中包含所有失真类型，即使使用参考样本，在不同实验中也可能会经常存在偏差。

ITU-T第9研究组（*SG9, stduy grop 9*）提出了若干建议作为主观和客观质量的评估方法，例如ITU-R BT.500-13[^2]和ITU-T P-系列建议。这些建议提供了：标准观察条件，观察者和测试材料的选择标准，评估程序和数据分析方法。 建议ITU-T P.910[^3]至P.913[^4]用于处理多媒体应用中的主观视频质量评估。建议的早期版本（例如，P.910，P.911[^5]）主要针对多媒体应用中的固定视频服务的范例而设计。这些范例认为视频信号通过可靠的连接传输到位于安静且无干扰的环境（例如起居室或办公室）中的固定阴极射线管（CRT）电视机。ITU-T引入了P. 913建议，用于适应新的应用（例如互联网视频）。

ITU-T P.913于2014年1月获得批准，建议描述了非交互式的主观评估方法，该方法用于评估单向视频（*one-way overall*）质量，音频质量和视听质量。P.913旨在覆盖一种新的视频范例，例如，视频点播服务，通过不可靠的链接传输至位于嘈杂环境的、使用LCD或其它平板显示器的、各种移动设备和固定设备。这种新范式影响了主观测试的关键特征，例如观看环境，收听环境和要回答的问题。新范例中的主观质量评估会增加先前建议中未考虑的问题。但是，P.913并未满足广播公司的专业需求。

测试镜头的数量、类型、持续时间以及主题数量，对于主观评估结果的解释至关重要。P.913建议测试视频的持续时间为5~20秒，最好为8~110秒。场景数量可以控制在4~6个。P.913要求需要至少24名受试者在受控环境中进行评估，并且至少35名受试者在公共环境中进行评估。较少的受试者可用于试点研究以指示视频质量的趋势。

## Subjective Quality Evaluation Methods and Metrics（主观质量评估方法和指标）
ITU-T P-系列定义了很多最常用的主观质量评估的方法。本节将会对其进行介绍。

## Absolute Category Rating（ACR，绝对等级评分）
绝对等级评分方法是一种对测试序列一次呈现一个，且在质量等级量表内进行独立评分的等
级判断[^6]。ACR也称为单刺激方法，其中观看者观看一个刺激（例如，视频剪辑）然后对其进行独立评级。ACR方法受到观看者对内容看法的影响，例如，观看者如果不喜欢制作的内容，他可能会给该视频较差的评分。

ACR使用下列的5种量级评价视频的总体质量：

| 5 | Excellent | 优秀 |
| --- | --- | --- |
| 4 | Good | 良好 |
| 3 | Fair | 普通 |
| 2 | Poor | 较差 |
| 1 | Bad | 差 |

带有隐参考的绝对等级评分方法绝对是一种对测试序列一次呈现一个，且在等级量表内
进行独立评分的等级判断。

还有一种ACR方法的变体——具有隐藏参考的ACR（ACR-HR）。 对于ACR-HR而言，实验包括每个视频片段的参考版本，参考版本不是作为一对的一部分，而是作为评级的独立刺激。在进行数据分析时，将计算每个测试序列和其对应 的(隐)参考间的差异质量评分(DMOS, differential mean opinion score)。这个步骤就是“隐参考”。

差异观测者(DV，differential viewer)分数在每个被试者/每个处理后的视频序列(PVS, processed video sequence)的基础上计算得出。通过下述公式，合适的隐参考(REF)被用于计算DV。

$$DV(PVS) = V(PVS) - V(REF) + 5$$

其中V是观测者的ACR分数。

使用此公式时，DV为5时表示质量“优秀”，为1时表示质量“差”。任何大于5的DV值(即，处理后的序列评分比其相关的隐参考序列高)，通常情况下被认为是有效的。否则，可应用如下的公式来预防这些单独的ACR-HR观测者分数 (DV)过度影响总体平均意见分数:

$$crushed\_DV = (7*DV)/(2+DV), \ \ s.t.\ \ DV>5$$

ACR-HR方法消除了来自ACR评级的内容的一些影响，但程度小于双刺激方法，这将在下面讨论。

## Degradation Category Rating（DCR，劣化等级评分）
劣化等级评分（DCR）也称为双刺激损害量表（DSIS, double stimulus impairment scale）方法，DCR中测试视频序列会成对呈现。首先呈现参考刺激，然后呈现经过处理和质量降级后的版本。在这种情况下，要求受试者对第二序列相对于参考序列的损伤进行评级。对于观看者对内容的影响而言，DCR受到的这种影响是最小的。因此，DCR能够检测ACR方法可能遗漏的颜色损伤和跳过错误。但是，因为DCR始终首先显示参考序列，因此DCR可能略有偏差。在DCR中，使用以下五种量级评价相对损害的等级：

| 5 | Imperceptible | 无感知的 |
| --- | --- | --- |
| 4 | Perceptible but not annoying | 可感知但不令人厌烦 |
| 3 | Slightly annoying | 轻微令人厌烦 |
| 2 | Annoying | 令人厌烦 |
| 1 | Very annoying | 非常令人厌烦 |

## Comparison Category Rating（比较等级评分）
比较等级评分（CCR）是一种双刺激方法，其中以随机顺序呈现相同刺激的两个版本。例如，可以有一半的时间首先显示参考序列，以及有一半的时间最后显示参考序列，并且以随机方式确定参考序列的显示顺序。CCR也称为双刺激比较量表（DSCS, double-stimulus comparison scale）方法。它可用于比较参考视频和处理过的视频，或比较两种不同的损伤。与DCR一样，CCR观察者对内容的看法的影响微乎其微。 然而，在CCR中，受试者可能会无意间交换了CCR中的分数，这将导致DCR或ACR中不存在的一种错误。在DCR中，使用以下七种量级。

| -3 | Much worse | 甚差 |
| --- | --- | --- |
| -2 | Worse | 较差 |
| -1 | Slightly worse | 稍差 |
| 0 | The same | 相同 |
| 1 | Slightly Better | 稍好 |
| 2 | Better | 较好 |
| 3 | Much Better | 甚好 |

## mean opinion score（MOS，平均主观得分）
平均主观得分（MOS）是主观视频质量评估中最常用的指标。MOS构成了主观质量评价方法的基础，也可作为客观评价指标的参考。在电话网络领域，使用MOS评估用户对网络质量的看法已有数十年之久。MOS也可用于音频领域的主观音频质量测量。在所有受试者进行实验之后，需要获取每个视频的平均得分以计算MOS或差异质量评分（DMOS）。

对于经过压缩和传输的视频而言，MOS提供了数字等级来表示用户对这些视频的感知质量。MOS通常表示为1~5的单个数字，其中1是最低感知质量，5是最高感知质量。MOS用于诸如ACR/ACR-HR的单刺激方法。在ACR/ACR-HR评估方法中，受试者对测试视频中的每一个视频进行单独评估。相反，DMOS分数测量相同刺激的两个版本（例如，源视频和处理后的视频）之间的质量变化。在平均差异观察者得分情况下的ACR-HR方法，DCR方法和CCR方法通常产生DMOS分数。

比较不同实验的MOS值需要仔细考虑实验内和实验间的变化。通常，只有来自相同测试类型的MOS值才能比较。例如，使用ACR标度MOS值不能直接与来自DCR实验的MOS值进行比较。另外，即使对相同测试类型的MOS进行比较，此时，即便对于相同的参与者，每个实验的结果也会略有不同。这种情况将会导致以下问题：

* 即使以相同的样本，相同的顺序进行重复实验，受试者给出的分数也很少保持一致。 通常这被认为是MOS分数上的一种噪声。
* **短期依赖**：因为受试者会受到他们先前评分的样本的短期影响，因此MOS会受到短时背景的影响。例如，在一个或两个不良样本之后，受试者倾向于将平庸的样本给出更高的评分。如果一个平庸的样本出现在非常好的样本之后，则受试者倾向给予平庸样本较低的评分。为了平衡这种短时依赖性，应该针对不同的受试者调整测试样本的呈现顺序。但是，这种策略并没有消除统计上的不确定性。
* **中期依赖**：与平均质量、质量分布有关的中期背景导致了主观实验之间的差异。例如，如果实验主要由低质量的样本组成，那么人们往往会给予它们一个更高的评分，反之亦然。这是因为人们倾向于使用实验中提供的全部质量量级，并使该量级适应实验中提出的质量。
* **长期依赖**：长期依赖性反映了受试者对类别标签的文化解释、对质量的文化态度以及语言依赖性。例如，某些人可能比其他人更频繁地使用视频内容。此外，对质量的期望可能会随着时间而改变。随着人们对数字视频的失真现象越来越了解，数字噪音也成为人们日常体验的一部分。

虽然如上的限制会导致实验之间的差异，但是却无法避免。但是，通过提供信息说明，均衡的测试设计，足够数量的参与者以及混合的演示顺序，可以最大限度地降低它们的影响。

[^1]: anchor字面意思是锚，是个把船固定的东西。anchor在计算机视觉中有锚点或锚框，目标检测中常出现的anchor box为锚框，表示固定的参考框。

[^2]: ITU-R BT.500-13: [Methodology for the Subjective Assessment of the Quality of Television Pictures](https://www.itu.int/rec/R-REC-BT.500/en).

[^3]: ITU-T P.910: [Subjective video quality assessment methods for multimedia applications](https://www.itu.int/itu-t/recommendations/rec.aspx?rec=9317).

[^4]: ITU-T P.913: [Methods for the subjective assessment of video quality, audio quality and audiovisual quality of Internet video and distribution quality television in any environment](https://www.itu.int/itu-t/recommendations/rec.aspx?rec=12775). 

[^5]: ITU-T P.911: [Subjective audiovisual quality assessment methods for multimedia applications](https://www.itu.int/itu-t/recommendations/rec.aspx?rec=4538).

[^6]: ITU-T P.910(C), 6.1, P12, 绝对等级评分法。 